---
title: "Scrape Congress"
author: "Erin M. Buchanan"
date: "3/17/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(rvest)
library(dplyr)
library(xml2)
library(stringr)
```

## Get List of Docs

```{r}
# example link
# "https://www.govinfo.gov/metadata/pkg/CREC-2022-03-16/mods.xml"

dates_pull <- seq(as.Date("2022-01-01"), as.Date("2022-12-31"), by="days")

dates_list <- list()

for (i in 1:length(dates_pull)){
  
  url <- paste0("https://www.govinfo.gov/metadata/pkg/CREC-", 
                dates_pull[i], 
                "/mods.xml")
  
  # try catch 
  read_congress <- function(url) {
    tryCatch( 
    { 
       example <- read_xml(url)
       error <- FALSE
      }, 
    error = function(e) { error <- TRUE } 
    )
  }
  
  results <- read_congress(url)
  
  if (!results) {
    
    example <- read_xml(url)  
    converted <- as_list(example)
    
    stuff <- converted$mods[grepl("relatedItem", names(converted$mods))]
    stuff <- unlist(stuff)
    df <- data.frame("name" = names(stuff), 
                     "part" = stuff)
    df <- subset(df, grepl(".htm$", part))
    df <- subset(df, grepl("PgS|PgH", part))
    
    df$where <- ifelse(
      grepl("PgS", df$part), "Senate", "House"
    )
    df$date <- as.character(dates_pull[i])
    
    dates_list[[i]] <- df
    
  }
  
  Sys.sleep(3)
  
}

df_full <- dplyr::bind_rows(dates_list)
```

## Data Clean Up

```{python}
# libraries
import requests
from bs4 import BeautifulSoup
import re
import time

# function to get the data
def get_text(url):
  # print(url)
  text = requests.get(url)
  clean_text = BeautifulSoup(text.content, "html.parser").get_text()
  clean_text = re.sub(r"{", "", clean_text)
  clean_text = re.sub(r"}", "", clean_text)
  clean_text = re.sub(r'\n', " ", clean_text)
  return clean_text

```


## Extract 

No want:
The SPEAKER pro tempore.
The ACTING PRESIDENT pro tempore.
Ms. DUCKWORTH thereupon assumed the Chair as Acting President pro tempore. 
The ACTING PRESIDENT pro tempore. The Senator from Minnesota. 
The PRESIDING OFFICER.

The clerk will call the roll.
The legislative clerk called the roll. [and what follows]

Do want:
Mr. SCHUMER.
Ms. BALDWIN.
Ms. GARCIA of Texas.
Mr. GOOD of Virginia.
Mrs. KIGGANS. 
Ms. JACKSON LEE.
Mr. AUSTIN SCOTT of Georgia.

Good example of full House record: https://www.govinfo.gov/content/pkg/CREC-2024-02-01/pdf/CREC-2024-02-01-house.pdf

Good example of full Senate record: https://www.govinfo.gov/content/pkg/CREC-2024-01-08/pdf/CREC-2024-01-08-senate.pdf
 
```{python}
def minimum(a, n):
    # inbuilt function to find the position of minimum
    minpos = a.index(min(a))
    return [minpos, min(a)]

# function to parse the data 
def get_starts(text):
  # name examples 
  # Mr. SCHUMER. Ms. BALDWIN.
  re1 = re.search(r'M[a-z]*\.\s[A-Z]*\.', text)
  # Ms. GARCIA of Texas. Mr. GOOD of Virginia.
  re2 = re.search(r'M[a-z]*\.\s[A-Z]*\sof\s[A-Z][a-z]*(\s[A-Z][a-z]*)?\.', text)
 
  # Ms. DeGETTE.
  # Mr. LaMALFA.
  # potentially MacCa something like that 
  re3 = re.search(r'M[a-z]*\.\s[A-Z]+[a-z]+[A-Z]+\.', text)
  re4 = re.search(r'M[a-z]*\.\s[A-Z]+[a-z]+[A-Z]+\sof\s[A-Z][a-z]*(\s[A-Z][a-z]*)?\.', text)
  
  # Ms. OCASIO-CORTEZ
  # Mr. D’ESPOSITO
  # Ms. DE LA CRUZ.
  # Ms. EDDIE BERNICE JOHNSON of Texas.
  # Ms. MAXINE WATERS of California.
  re5 = re.search(r"M[a-z]*\.\s[A-Z'’\-\s]*\.", text)
  re6 = re.search(r"M[a-z]*\.\s[A-Z'’\-\s]*\sof\s[A-Z][a-z]*(\s[A-Z][a-z]*)?\.", text)
  
  ## DO NOT WANT - should be in there then we delete those files 
  # The CHAIR.
  # The SPEAKER pro tempore.
  # The PRESIDING OFFICER.
  # The PRESIDING OFFICER (Mr. Rounds).
  # The PRESIDING OFFICER (Mrs. Fischer).
  # The Acting CHAIR.
  # The ACTING PRESIDENT pro tempore.
  re7 = re.search(r'The CHAIR[a-zA-Z\s\(]*\.|The SPEAKER[a-zA-Z\s\(]*\.|The (Presiding|PRESIDING) OFFICER[a-zA-Z\s\(]*\.|The (Acting|ACTING) CHAIR[a-zA-Z\s\(]*\.|The (Acting|ACTING) PRESIDENT[a-zA-Z\s\(]*\.|The PRESIDING OFFICER\.', text)
  
  # figure out which is lowest 
  re_list_start = [re1.start() if re1 else float('inf'), re2.start() if re2 else float('inf'), re3.start() if re3 else float('inf'), re4.start() if re4 else float('inf'), re5.start() if re5 else float('inf'), re6.start() if re6 else float('inf'), re7.start() if re7 else float('inf')]
  
  re_list_end = [re1.end() if re1 else float('inf'), re2.end() if re2 else float('inf'), re3.end() if re3 else float('inf'), re4.end() if re4 else float('inf'), re5.end() if re5 else float('inf'), re6.end() if re6 else float('inf'), re7.end() if re7 else float('inf') ]
  
  re_list = [re1, re2, re3, re4, re5, re6, re7]
    
  # as long as they aren't all infinity 
  if all(x == float('inf') for x in re_list_start):
    # move on to next thingy
    return "None"
  else: 
    min_index = minimum(re_list_start, len(re_list_start))
    start = re_list_start[min_index[0]]
    end = re_list_end[min_index[0]]
    name = text[start:end]
    new_text = text[end:]
    return [name, new_text, re_list[min_index[0]]]
 
```

```{python}
# get the data
df_full = r.df_full

# temp = df_full[df_full['where'] == "House"]
# temp = temp[temp['date'] == "2017-01-05"]
# temp = temp.reset_index()

# get the information you need as a list
links = df_full['part'].to_list()
where = df_full['where'].to_list()
dates = df_full['date'].to_list()

# links = temp['part'].to_list()
# where = temp['where'].to_list()
# dates = temp['date'].to_list()
```

```{python}
# looping variable
i = 1

# for every link the year 
for link in links[i: ]:
  
  # get the text for that link 
  texts = get_text(link)
  #print(texts)
  #print("__\n")
  
  # then we would loop over each text  
  while texts:
    # so we would get starts
    try_one = get_starts(texts)
    
    # break if try_one is none
    if try_one == "None": break 
    
    # then we would test if the new text has one 
    try_two = get_starts(try_one[1])
    
    # test
    # print(try_one[2])
    # print("__\n")
    # print(try_two[2])
    # print("__\n")
    # print(texts[0:100])
    # print("-------------\n")
    
    # if no other stuff then save the shit 
    if try_two == 'None': 
      # append if they keep yapping 
      f = open("temp/" + try_one[0] + where[i] + "." + dates[i] + '.txt', "a")  
      f.write(try_one[1])
      f.close()
      break 
    else: 
      f = open("temp/" + try_one[0] + where[i] + "." + dates[i] + '.txt', "a") 
      # only print to the start of the next one
      f.write(try_one[1][:try_two[2].start()])
      # be sure to use start so you get the next name 
      texts = try_one[1][try_two[2].start(): ]
      # loop back to the top 
  
  # reset i for the labels
  i = i + 1
  
  # take a small nap
  time.sleep(3)
```
