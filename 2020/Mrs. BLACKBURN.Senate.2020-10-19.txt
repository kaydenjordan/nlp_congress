 Mr. President, it doesn't take a genius to figure out  that there is a small but very loud sector of the American people who  are willing to condition their tolerance for diverging viewpoints on  how they feel, they themselves feel about what is being said,  worshipped, or reported. And as scary and as frightening as that  attitude is to many of us, it is increasingly reflected in the very  companies that have the most influence over how we access and consume  information.   Last week, we saw two of these companies go to extremes to get in  line with radicals who are trying to block, censor, and intimidate  their way into power. We all know the companies and the controversy I  am talking about. Twitter and Facebook censored the spread of a New  York Post article containing allegations that could potentially affect  the outcome of the upcoming election.   That is all I am going to say about the article itself because,  frankly, the content bears no importance on how anyone should react to  what happened after it was posted. Someone working for a private  company--someone who is a content reviewer or content moderator-- someone working for a private company made a unilateral decision to  stop Americans from reading the article. They didn't like it. They  said: I have the power to stop it, and because I have that power, I am  going to stop it.   Now that is precisely what happened, and I will tell you, colleagues,  it is not just that they blocked the link and the text of the article,  it is that at least in Twitter's case, they suspended the Trump  campaign's account; they suspended the New York Post account; they  locked the White House Press Secretary's account; and they suppressed  information posted by the House Judiciary Committee Republicans. They  couldn't even provide a plausible explanation for why they did this.  Think about that.   They made themselves the arbiters of free speech, and they, in their  almighty position, decided they were going to determine what you could  hear, when you could hear it, and how you could hear it. They decided.   The common element, of course, in all of this action that took place  was the New York Post story. Was it information or hacked information  or just inconvenient information? No one seems to want to answer that  question. Why do they not want to answer that question? It is because  they didn't like the information. It did not suit their narrative, but  the way things stand, they didn't have to, because there is no real  accountability and now their weak explanations have been co-opted into  arguments made by activists, rival media organizations, and even  journalists who were insisting that the information is harmful and must  be stricken from the record.    I would be happy to yield to the Democratic leader.  [[Page S6053]]         Thank you very much, Mr. President. I have to tell  you, listening to the Democratic leader there, this is one of the  things that social media has taken off on.   They lost. They lost the 2016 Presidential election, and they have  never accepted the results. Never. It doesn't fit their narrative. So  what do they do? Look at this. Let's just not even work. Let's just  adjourn. Let's not do our constitutional duty.   I tell you what, you can't make this stuff up. You really can't.  Cognitive dissonance of this moment in history has overwhelmed the  discourse.   It is important to make it abundantly clear that the outrage--the  absolute outrage from the American people over this incident with  social media has everything to do with their very fluid and subjective  standards that these companies use to control the flow of information,  and over the last few years, they have gotten worse about it. And you  know what? They do it until we slap their hands and then pull them back  in, and we say: You can't do this.   Now, in the case that we are discussing that happened last week, it  looks suspiciously like they applied a brandnew set of standards  because someone got spooked at the prospect of losing momentum on a  political narrative.   They are all working together on this. So let's go home; let's not  work; let's not do our job; let's bury a story on social media. Why?  Their gal didn't win in 2016, and Donald Trump did because the American  people said: We are with him, not her.   Now, here in Washington we can argue all over election-year politics,  but in Tennessee, the people are seeing this for what it is, and they  are not talking about politics. They think this is pretty terrifying.  They are seeing a news platform censor the news, and they are seeing  extremely powerful people cheer it on. To them and to me, that is  frightening.   They are looking to us to get into one of those policy debates my  colleagues across the aisle were so eager to jump into just last week  during Judge Barrett's confirmation hearing.   Fortunately, for them, we have got a head start on that discussion.  Big Tech has spent the last several years building up a body of  evidence against its own intentions, and if we don't address their  growing influence, we will lose our ability to create responsive  policy.   I have already come to the floor several times to speak on various  ways we are doing this--through legislation, antitrust investigations,  and some good old-fashioned committee hearings. Congress doing its job,  precisely why we ought not to adjourn, precisely why we should stay  here and do our work.   On October 28, the Commerce Committee will host a few familiar faces  for a hearing where we will analyze the effect that the liability  shield found in section 230 of the Communications Decency Act has on  Big Tech's behavior. Over the course of the hearing, we will speak with  Jack Dorsey of Twitter, Mark Zuckerberg of Facebook, and Sundar Pichai  of Google about their approach to using the section 230 shield.   We will also examine various legislative proposals to modernize  section 230, including one of my own that would resolve some  ambiguities regarding what sorts of content moderation policies are  shielded from liability and which ones aren't protected. We are going  to talk about the unintended consequences that stem from these  policies. We are going to talk about their platforms' interaction with  activists and with the media.   I think we will probably get around to talking about it, whether they  like it or not, because we have the bipartisan and unanimously  authorized subpoenas in hand to do it, and those subpoenas are good  through the end of this Congress.   Hopefully, by going straight to the top, we will gain a better  understanding of why these companies can't seem to regulate themselves,  why they can't seem to stop themselves from having a complete meltdown  every single time we turn up the heat and talk about these issues of  privacy, talk about censorship, talk about prioritization, talk about  preferencing, talk about holding them accountable for the spectrum they  use to put out their message and the activity that they are taking now  to censor the free speech of the American public.   I yield the floor.   